{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5455055-b255-4552-b0b5-d59740875eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel, cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import matplotlib as plt\n",
    "from scipy.stats import pearsonr, wasserstein_distance\n",
    "from scipy.spatial import procrustes\n",
    "import networkx as nx\n",
    "from scipy.sparse.csgraph import shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1136efb-cbeb-4ff2-af9a-4736eab73a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_kmac(Y_ker, Y_gr, epsilon=0.1, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Compute the kernel measure of association (KMAc) between two modalities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Y_ker : ndarray of shape (n, d_ker)\n",
    "        Data samples for the modality used for computing kernel similarity.\n",
    "    Y_gr : ndarray of shape (n, d_gr)\n",
    "        Data samples for the modality used for constructing the geometric graph.\n",
    "    epsilon : float, optional\n",
    "        Distance threshold for connecting nodes in the geometric graph.\n",
    "    sigma : float, optional\n",
    "        Bandwidth parameter for the RBF kernel.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kmac_value : float\n",
    "        The computed kernel measure of association.\n",
    "    \"\"\"\n",
    "    n = Y_ker.shape[0]  # Number of samples\n",
    "\n",
    "    # Step 1: Compute kernel matrix K(Y_ker, Y_ker) using the RBF kernel\n",
    "    K_matrix = rbf_kernel(Y_ker, Y_ker, gamma=1/(2 * sigma**2))\n",
    "\n",
    "    # Step 2: Construct the geometric graph G_n using Y_gr\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Ensure all nodes are in the graph\n",
    "    G.add_nodes_from(range(n))  \n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if np.linalg.norm(Y_gr[i, :] - Y_gr[j, :]) < epsilon:  # Connect if within threshold\n",
    "                G.add_edge(i, j)\n",
    "\n",
    "    # Compute degrees safely\n",
    "    degrees = np.array([G.degree[i] if i in G.nodes else 0 for i in range(n)])  # âœ… FIXED\n",
    "    degrees[degrees == 0] = 1  # Avoid division by zero\n",
    "\n",
    "    # Step 3: Compute numerator\n",
    "    first_term = np.mean([\n",
    "        (1 / degrees[i]) * sum(K_matrix[i, j] for j in G.neighbors(i))\n",
    "        for i in range(n) if degrees[i] > 0\n",
    "    ]) if n > 1 else 0  # Ensure valid mean computation\n",
    "\n",
    "    second_term = np.sum(K_matrix) / (n * (n - 1)) if n > 1 else 0  # Avoid division by zero\n",
    "\n",
    "    numerator = first_term - second_term\n",
    "\n",
    "    # Step 4: Compute denominator (kernel variance term)\n",
    "    kernel_variance = np.sum([\n",
    "        np.linalg.norm(K_matrix[i, :] - K_matrix[j, :])**2\n",
    "        for i in range(n) for j in range(n) if i != j\n",
    "    ]) / (2 * n * (n - 1)) if n > 1 else 1  # Avoid division by zero\n",
    "\n",
    "    return numerator / kernel_variance if kernel_variance != 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c22bc83f-956a-4700-a064-8326d406cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Hilbert-Schmidt Independence Criterion (HSIC)\n",
    "def kernel_similarity(X, Y, sigma=1.0):\n",
    "    \"\"\"Computes similarity using HSIC with RBF kernel.\"\"\"\n",
    "    K_X = rbf_kernel(X, X, gamma=1/(2*sigma**2))\n",
    "    K_Y = rbf_kernel(Y, Y, gamma=1/(2*sigma**2))\n",
    "    return np.mean(K_X * K_Y)\n",
    "\n",
    "# 2. PCA-based Correlation Similarity\n",
    "def pca_correlation_similarity(X, Y, n_components=5):\n",
    "    \"\"\"Computes similarity using PCA and correlation.\"\"\"\n",
    "    pca_X = PCA(n_components=n_components).fit_transform(X)\n",
    "    pca_Y = PCA(n_components=n_components).fit_transform(Y)\n",
    "    correlations = [pearsonr(pca_X[:, i], pca_Y[:, i])[0] for i in range(n_components)]\n",
    "    return np.mean(correlations)\n",
    "\n",
    "# 3. Canonical Correlation Analysis (CCA)\n",
    "def cca_similarity(X, Y, n_components=2):\n",
    "    \"\"\"Computes similarity using Canonical Correlation Analysis (CCA).\"\"\"\n",
    "    cca = CCA(n_components=n_components)\n",
    "    X_c, Y_c = cca.fit_transform(X, Y)\n",
    "    return np.mean(np.corrcoef(X_c.T, Y_c.T)[0:n_components, n_components:])\n",
    "\n",
    "# 4. Procrustes Analysis\n",
    "def procrustes_similarity(X, Y):\n",
    "    \"\"\"Computes similarity using Procrustes analysis (alignment-based).\"\"\"\n",
    "    mtx1, mtx2, disparity = procrustes(X, Y)\n",
    "    return 1 - disparity  # Similarity is inverse of disparity\n",
    "\n",
    "# 5. Wasserstein Distance\n",
    "def wasserstein_similarity(X, Y):\n",
    "    \"\"\"Computes similarity using the Wasserstein distance (Earth Mover's Distance).\"\"\"\n",
    "    return -wasserstein_distance(X.ravel(), Y.ravel())  # Convert to similarity\n",
    "\n",
    "# 6. Graph-Based Diffusion Similarity\n",
    "def graph_diffusion_similarity(X, Y, k=5):\n",
    "    \"\"\"Computes similarity using graph-based diffusion distance.\"\"\"\n",
    "    G_X = nx.k_nearest_neighbors(nx.Graph(), X, k)\n",
    "    G_Y = nx.k_nearest_neighbors(nx.Graph(), Y, k)\n",
    "\n",
    "    D_X = shortest_path(nx.to_numpy_array(G_X))\n",
    "    D_Y = shortest_path(nx.to_numpy_array(G_Y))\n",
    "\n",
    "    return -np.linalg.norm(D_X - D_Y)  # Negative norm as similarity\n",
    "\n",
    "# 7. Hilbert-Schmidt Similarity (HSS)\n",
    "def hilbert_schmidt_similarity(Y1, Y2, epsilon=0.1, sigma=1.0):\n",
    "    \"\"\"Computes the Hilbert-Schmidt Similarity (HSS) between two modalities.\"\"\"\n",
    "    kmac_1 = compute_kmac(Y1, Y2, epsilon=epsilon, sigma=sigma)\n",
    "    kmac_2 = compute_kmac(Y2, Y1, epsilon=epsilon, sigma=sigma)\n",
    "    return 0.5 * (kmac_1 + kmac_2)  # Symmetrization\n",
    "\n",
    "# 8. Cosine Similarity (Only if Dimensions Match)\n",
    "def cosine_similarity_if_same_dim(X, Y):\n",
    "    \"\"\"Computes cosine similarity only if dimensions match.\"\"\"\n",
    "    if X.shape[1] != Y.shape[1]:\n",
    "        raise ValueError(\"Cosine similarity requires both modalities to have the same dimension.\")\n",
    "    return np.mean(cosine_similarity(X, Y))  # Average over all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12204a4a-0952-45bb-a700-09bcff70cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModalityClusterer:\n",
    "    \"\"\"\n",
    "    A class for computing similarity matrices and clustering modalities.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    modalities : list of ndarrays\n",
    "        A list of modality matrices, where each matrix has shape (n, d_k).\n",
    "    similarity_matrix : ndarray\n",
    "        Stores the computed similarity matrix for reuse.\n",
    "    linkage_matrix : ndarray\n",
    "        Stores the hierarchical clustering linkage matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, modalities):\n",
    "        \"\"\"\n",
    "        Initialize the ModalityClusterer with a list of modalities.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        modalities : list of ndarrays\n",
    "            A list of m modality matrices, where each matrix has shape (n, d_k).\n",
    "        \"\"\"\n",
    "        self.modalities = modalities\n",
    "        self.similarity_matrix = None\n",
    "        self.linkage_matrix = None  # Stores linkage matrix for dendrograms\n",
    "\n",
    "    def compute_similarity_matrix(self, similarity_metric=\"hss\", **kwargs):\n",
    "        \"\"\"\n",
    "        Compute the similarity matrix between modalities using the specified similarity metric.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        similarity_metric : str, optional\n",
    "            The similarity function to use. Options: \"hss\", \"hsic\", \"pca\", \"cca\",\n",
    "            \"procrustes\", \"wasserstein\", \"graph_diffusion\", \"cosine\".\n",
    "        kwargs : dict\n",
    "            Additional parameters for similarity functions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        similarity_matrix : ndarray of shape (m, m)\n",
    "            The computed similarity matrix between modalities.\n",
    "        \"\"\"\n",
    "        m = len(self.modalities)\n",
    "        self.similarity_matrix = np.zeros((m, m))\n",
    "\n",
    "        similarity_functions = {\n",
    "            \"hss\": hilbert_schmidt_similarity,\n",
    "            \"hsic\": kernel_similarity,\n",
    "            \"pca\": pca_correlation_similarity,\n",
    "            \"cca\": cca_similarity,\n",
    "            \"procrustes\": procrustes_similarity,\n",
    "            \"wasserstein\": wasserstein_similarity,\n",
    "            \"graph_diffusion\": graph_diffusion_similarity,\n",
    "            \"cosine\": cosine_similarity_if_same_dim\n",
    "        }\n",
    "\n",
    "        if similarity_metric not in similarity_functions:\n",
    "            raise ValueError(f\"Invalid similarity metric. Choose from {list(similarity_functions.keys())}\")\n",
    "\n",
    "        similarity_function = similarity_functions[similarity_metric]\n",
    "\n",
    "        for i in range(m):\n",
    "            for j in range(i, m):\n",
    "                try:\n",
    "                    sim = similarity_function(self.modalities[i], self.modalities[j], **kwargs)\n",
    "                    self.similarity_matrix[i, j] = sim\n",
    "                    self.similarity_matrix[j, i] = sim  # Ensure symmetry\n",
    "                except ValueError as e:\n",
    "                    print(f\"Skipping similarity computation for ({i}, {j}): {e}\")\n",
    "\n",
    "        return self.similarity_matrix\n",
    "\n",
    "    def cluster_modalities(self, similarity_metric=\"hss\", num_clusters=None, threshold=None, method=\"average\", **kwargs):\n",
    "        \"\"\"\n",
    "        Perform hierarchical clustering on modalities based on a computed similarity matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        similarity_metric : str, optional\n",
    "            The similarity function to use. Options: \"hss\", \"hsic\", \"pca\", \"cca\", \n",
    "            \"procrustes\", \"wasserstein\", \"graph_diffusion\", \"cosine\".\n",
    "        num_clusters : int, optional\n",
    "            The desired number of clusters. If None, threshold must be provided.\n",
    "        threshold : float, optional\n",
    "            The distance threshold for forming clusters. If None, num_clusters must be provided.\n",
    "        method : str, optional\n",
    "            The linkage method for clustering (default is \"average\").\n",
    "        kwargs : dict\n",
    "            Additional parameters for similarity functions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cluster_labels : ndarray of shape (m,)\n",
    "            Cluster labels for each modality.\n",
    "        \"\"\"\n",
    "        # Compute similarity matrix if not already computed\n",
    "        if self.similarity_matrix is None:\n",
    "            self.compute_similarity_matrix(similarity_metric, **kwargs)\n",
    "\n",
    "        # Convert similarity to distance (1 - similarity)\n",
    "        distance_matrix = 1 - self.similarity_matrix\n",
    "        np.fill_diagonal(distance_matrix, 0)  # Ensure diagonal is zero\n",
    "\n",
    "        # Convert to condensed distance matrix for scipy\n",
    "        condensed_distance = sch.distance.squareform(distance_matrix)\n",
    "\n",
    "        # Perform hierarchical clustering\n",
    "        self.linkage_matrix = sch.linkage(condensed_distance, method=method)\n",
    "\n",
    "        # Determine cluster labels\n",
    "        if num_clusters is not None:\n",
    "            cluster_labels = sch.fcluster(self.linkage_matrix, num_clusters, criterion='maxclust')\n",
    "        elif threshold is not None:\n",
    "            cluster_labels = sch.fcluster(self.linkage_matrix, threshold, criterion='distance')\n",
    "        else:\n",
    "            raise ValueError(\"Either num_clusters or threshold must be provided.\")\n",
    "\n",
    "        return cluster_labels\n",
    "\n",
    "    def plot_dendrogram(self, labels=None, title=\"Dendrogram of Modality Clustering\"):\n",
    "        \"\"\"\n",
    "        Plot the hierarchical clustering dendrogram.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : list of str, optional\n",
    "            Labels for each modality. If None, defaults to numerical labels.\n",
    "        title : str, optional\n",
    "            Title for the dendrogram plot.\n",
    "        \"\"\"\n",
    "        if self.linkage_matrix is None:\n",
    "            raise ValueError(\"Clustering has not been performed. Run `cluster_modalities` first.\")\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        sch.dendrogram(self.linkage_matrix, labels=labels, leaf_rotation=90, leaf_font_size=12)\n",
    "        plt.title(title)\n",
    "        plt.xlabel(\"Modalities\")\n",
    "        plt.ylabel(\"Distance\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "835f2cb8-f93f-4c62-a1b8-4c231befa909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix (HSS):\n",
      " [[-0.25900012 -0.30598359 -0.26641375]\n",
      " [-0.30598359 -0.32459244 -0.29783419]\n",
      " [-0.26641375 -0.29783419 -0.15728356]]\n",
      "Cluster Labels: [1 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data for 3 modalities\n",
    "np.random.seed(42)\n",
    "modality_1 = np.random.rand(100, 5)  # 100 samples, 5 features\n",
    "modality_2 = np.random.rand(100, 6)  # 100 samples, 6 features\n",
    "modality_3 = np.random.rand(100, 4)  # 100 samples, 4 features\n",
    "\n",
    "modalities = [modality_1, modality_2, modality_3]\n",
    "\n",
    "# Initialize the ModalityClusterer\n",
    "clusterer = ModalityClusterer(modalities)\n",
    "\n",
    "# Compute similarity matrix using Hilbert-Schmidt Similarity\n",
    "similarity_matrix = clusterer.compute_similarity_matrix(similarity_metric=\"hss\", epsilon=0.2, sigma=1.0)\n",
    "print(\"Similarity Matrix (HSS):\\n\", similarity_matrix)\n",
    "\n",
    "# Perform clustering using the computed similarity matrix\n",
    "cluster_labels = clusterer.cluster_modalities(similarity_metric=\"hss\", num_clusters=2)\n",
    "print(\"Cluster Labels:\", cluster_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf186d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339254e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hierarchical_amp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
