{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9e9adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Script started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running for rho = 0.8 ===\n",
      "\n",
      "=== Current trial for n = 1000, trial = 1 ===\n",
      "[1 1 2]\n",
      "1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    0\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    0    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    0    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    0\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    0\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    0    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    0\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    0\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    0\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    0    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    0    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    0    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    0\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    0    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    0\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    0    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    1\n",
      "[3,]    1    1\n",
      "\n",
      "=== Current trial for n = 1000, trial = 2 ===\n",
      "[1 1 2]\n",
      "1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    0\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    0    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    0    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    0\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    0\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    0    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    0\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    0\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    0\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    0    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    0    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    0    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    0\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    0    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    0\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    0    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    1\n",
      "[3,]    1    1\n",
      "\n",
      "=== Current trial for n = 1000, trial = 3 ===\n",
      "[1 1 2]\n",
      "1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    0\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    0    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    0    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    0\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    0\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    0    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    0\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    0\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    0\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    0    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    0    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    0    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    0\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    0    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    1\n",
      "[3,]    1    0\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    0\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    0\n",
      "[2,]    1    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    1    1\n",
      "[3,]    0    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    1    1\n",
      "[2,]    0    1\n",
      "[3,]    1    1\n",
      "Now checking the following component structure:\n",
      "     [,1] [,2]\n",
      "[1,]    0    1\n",
      "[2,]    1    1\n",
      "[3,]    1    1\n",
      "\n",
      "=== Current trial for n = 1000, trial = 4 ===\n",
      "[1 1 2]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 245\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>>> Results saved to Results/vary_rho_com_meth/rho_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrho\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_n_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 207\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    204\u001b[0m r_list     \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    205\u001b[0m p_list     \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(g \u001b[38;5;241m*\u001b[39m n) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m gamma_list]\n\u001b[0;32m--> 207\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mrun_amp_rho_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamp_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    216\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# --- Save results as CSV ---\u001b[39;00m\n\u001b[1;32m    219\u001b[0m rows \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[3], line 109\u001b[0m, in \u001b[0;36mrun_amp_rho_experiment\u001b[0;34m(n, p_list, r_list, rho, num_trials, amp_iters, num_clusters, threshold)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# --- AMP with clustering (HSS) ---\u001b[39;00m\n\u001b[1;32m    108\u001b[0m pipe_cluster \u001b[38;5;241m=\u001b[39m MultimodalPCAPipelineClustering()\n\u001b[0;32m--> 109\u001b[0m result_cluster \u001b[38;5;241m=\u001b[39m \u001b[43mpipe_cluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise_amp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamp_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamp_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43msimilarity_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcca\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    114\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m U_cluster \u001b[38;5;241m=\u001b[39m result_cluster[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mU_denoised\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# --- AMP without clustering (distinct) ---\u001b[39;00m\n",
      "File \u001b[0;32m~/Research/Hierarchical_AMP/Python_scripts/complete_pipeline.py:793\u001b[0m, in \u001b[0;36mMultimodalPCAPipelineClusteringSimulation.denoise_amp\u001b[0;34m(self, X_list, K_list, cluster_labels_U, compute_clusters, num_clusters, threshold, amp_iters, muteu, mutev, preprocess, similarity_method)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_model_u \u001b[38;5;241m=\u001b[39m emp_bayes\u001b[38;5;241m.\u001b[39mClusterEmpiricalBayes(U_normalized_list, M_matrices_u, S_matrices_u, cluster_labels_U)\n\u001b[1;32m    791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_model_v \u001b[38;5;241m=\u001b[39m emp_bayes\u001b[38;5;241m.\u001b[39mClusterEmpiricalBayes(V_normalized_list, M_matrices_v, S_matrices_v, np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(X_list)))\n\u001b[0;32m--> 793\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_model_u\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_cluster_priors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_model_v\u001b[38;5;241m.\u001b[39mestimate_cluster_priors()\n\u001b[1;32m    796\u001b[0m \u001b[38;5;66;03m# Step 5: Run AMP\u001b[39;00m\n",
      "File \u001b[0;32m~/Research/Hierarchical_AMP/Python_scripts/emp_bayes.py:493\u001b[0m, in \u001b[0;36mClusterEmpiricalBayes.estimate_cluster_priors\u001b[0;34m(self, em_iter, nsupp_ratio, max_nsupp)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# Estimate prior using empirical Bayes\u001b[39;00m\n\u001b[1;32m    492\u001b[0m nonpar_eb \u001b[38;5;241m=\u001b[39m NonparEB(em_iter\u001b[38;5;241m=\u001b[39mem_iter, nsupp_ratio\u001b[38;5;241m=\u001b[39mnsupp_ratio, max_nsupp\u001b[38;5;241m=\u001b[39mmax_nsupp)\n\u001b[0;32m--> 493\u001b[0m support_points, prior_weights \u001b[38;5;241m=\u001b[39m \u001b[43mnonpar_eb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_prior\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS_cluster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;66;03m# Store prior per cluster\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_priors[cluster] \u001b[38;5;241m=\u001b[39m (support_points, prior_weights)\n",
      "File \u001b[0;32m~/Research/Hierarchical_AMP/Python_scripts/emp_bayes.py:252\u001b[0m, in \u001b[0;36mNonparEB.estimate_prior\u001b[0;34m(self, f, mu, cov)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mestimate_prior\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, mu, cov):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     covInv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mpinv(cov)  \u001b[38;5;66;03m# Use pseudo-inverse for stability\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m=\u001b[39m _npmle_em_hd(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mZ, mu, covInv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mem_iter)\n",
      "File \u001b[0;32m~/Research/Hierarchical_AMP/Python_scripts/emp_bayes.py:244\u001b[0m, in \u001b[0;36mNonparEB._check_init\u001b[0;34m(self, f, mu)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m# f is an (n_samples x n_features) matrix\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnsupp, n_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m--> 244\u001b[0m     \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# Get indices of samples closest to each cluster center\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     closest, _ \u001b[38;5;241m=\u001b[39m pairwise_distances_argmin_min(kmeans\u001b[38;5;241m.\u001b[39mcluster_centers_, f)\n",
      "File \u001b[0;32m~/miniconda3/envs/HierarchicalAMP/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/HierarchicalAMP/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1510\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1507\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[0;32m-> 1510\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1526\u001b[0m     inertia \u001b[38;5;241m<\u001b[39m best_inertia\n\u001b[1;32m   1527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[1;32m   1528\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/HierarchicalAMP/lib/python3.10/site-packages/sklearn/utils/parallel.py:165\u001b[0m, in \u001b[0;36m_threadpool_controller_decorator.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m controller \u001b[38;5;241m=\u001b[39m _get_threadpool_controller()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m controller\u001b[38;5;241m.\u001b[39mlimit(limits\u001b[38;5;241m=\u001b[39mlimits, user_api\u001b[38;5;241m=\u001b[39muser_api):\n\u001b[0;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/HierarchicalAMP/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:750\u001b[0m, in \u001b[0;36m_kmeans_single_lloyd\u001b[0;34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict_convergence:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;66;03m# rerun E-step so that predicted labels match cluster centers\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     lloyd_iter(\n\u001b[1;32m    739\u001b[0m         X,\n\u001b[1;32m    740\u001b[0m         sample_weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m         update_centers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    748\u001b[0m     )\n\u001b[0;32m--> 750\u001b[0m inertia \u001b[38;5;241m=\u001b[39m \u001b[43m_inertia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels, inertia, centers, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_modules():\n",
    "    # Set path to the Python_Scripts directory\n",
    "    project_root = os.path.abspath(\"../Python_scripts\")\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.append(project_root)\n",
    "\n",
    "    # Import and reload your core modules\n",
    "    global amp, pca_pack, preprocessing, emp_bayes, hierarchical, pipeline\n",
    "    amp = importlib.import_module(\"amp\")\n",
    "    pca_pack = importlib.import_module(\"pca_pack\")\n",
    "    preprocessing = importlib.import_module(\"preprocessing\")\n",
    "    emp_bayes = importlib.import_module(\"emp_bayes\")\n",
    "    hierarchical = importlib.import_module(\"hierarchical_clustering_modalities\")\n",
    "    pipeline = importlib.import_module(\"complete_pipeline\")\n",
    "\n",
    "    importlib.reload(amp)\n",
    "    importlib.reload(pca_pack)\n",
    "    importlib.reload(preprocessing)\n",
    "    importlib.reload(emp_bayes)\n",
    "    importlib.reload(hierarchical)\n",
    "    importlib.reload(pipeline)\n",
    "\n",
    "    # Extract key classes/functions\n",
    "    global ebamp_multimodal, MultiModalityPCA, MultiModalityPCADiagnostics\n",
    "    global ClusterEmpiricalBayes, ModalityClusterer\n",
    "    global MultimodalPCAPipeline, MultimodalPCAPipelineClustering\n",
    "    global AJIVEreconstructor, MCCA_denoiser, GCCA_denoiser, DISCO_denoiser, MFA_denoiser, HPCA_denoiser\n",
    "\n",
    "    ebamp_multimodal = amp.ebamp_multimodal\n",
    "    MultiModalityPCA = pca_pack.MultiModalityPCA\n",
    "    MultiModalityPCADiagnostics = preprocessing.MultiModalityPCADiagnostics\n",
    "    ClusterEmpiricalBayes = emp_bayes.ClusterEmpiricalBayes\n",
    "    ModalityClusterer = hierarchical.ModalityClusterer\n",
    "    MultimodalPCAPipeline = pipeline.MultimodalPCAPipelineSimulation\n",
    "    MultimodalPCAPipelineClustering = pipeline.MultimodalPCAPipelineClusteringSimulation\n",
    "\n",
    "    # Import and reload other integration methods\n",
    "    import other_multimodal\n",
    "    importlib.reload(other_multimodal)\n",
    "    AJIVEreconstructor = other_multimodal.AJIVEReconstructor\n",
    "    MCCA_denoiser = other_multimodal.MCCAJointIndividual\n",
    "    GCCA_denoiser = other_multimodal.GCCAJointIndividual\n",
    "    DISCO_denoiser = other_multimodal.DISCO_SCA\n",
    "    MFA_denoiser = other_multimodal.MFAJointIndividual\n",
    "    HPCA_denoiser = other_multimodal.HPCA\n",
    "\n",
    "\n",
    "def generate_rademacher(shape):\n",
    "    return np.random.choice([-1, 1], size=shape)\n",
    "\n",
    "\n",
    "def reconstruction_error(U_est, U_true):\n",
    "    P_est = U_est @ U_est.T\n",
    "    P_true = U_true @ U_true.T\n",
    "    return np.linalg.norm(P_est - P_true, 'fro')**2 / (U_true.shape[0]**2)\n",
    "\n",
    "\n",
    "def run_amp_rho_experiment(n, p_list, r_list, rho, num_trials, amp_iters, num_clusters=None, threshold=None):\n",
    "    print(f\"\\n=== Running for rho = {rho} ===\", flush=True)\n",
    "\n",
    "    errors_clustered = {i: [] for i in range(3)}\n",
    "    errors_distinct = {i: [] for i in range(3)}\n",
    "    # prepare storage for other methods: 6 methods × 3 blocks\n",
    "    errors_ajive  = {i: [] for i in range(3)}\n",
    "    errors_mcca   = {i: [] for i in range(3)}\n",
    "    errors_gcca   = {i: [] for i in range(3)}\n",
    "    errors_disco  = {i: [] for i in range(3)}\n",
    "    errors_mfa    = {i: [] for i in range(3)}\n",
    "    errors_hpca   = {i: [] for i in range(3)}\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        print(f\"\\n=== Current trial for n = {n}, trial = {trial+1} ===\", flush=True)\n",
    "\n",
    "        U1 = generate_rademacher((n, r_list[0]))\n",
    "        epsilon = generate_rademacher((n, ))\n",
    "\n",
    "        U2 = np.hstack([U1[:, :r_list[0]], generate_rademacher((n, r_list[1] - r_list[0]))])\n",
    "        U3 = generate_rademacher((n, r_list[2]))\n",
    "        U_true = [U1, U2, U3]\n",
    "\n",
    "        V1 = generate_rademacher((p_list[0], r_list[0]))\n",
    "        V2 = generate_rademacher((p_list[1], r_list[1]))\n",
    "        V3 = generate_rademacher((p_list[2], r_list[2]))\n",
    "\n",
    "        D1 = np.diag([5 * (i+1) for i in range(r_list[0])])\n",
    "        D2 = np.diag([5 * (i+1) for i in range(r_list[1])])\n",
    "        D3 = np.diag([5 * (i+1) for i in range(r_list[2])])\n",
    "\n",
    "        Z1 = np.random.randn(n, p_list[0]) / np.sqrt(n)\n",
    "        Z2 = np.random.randn(n, p_list[1]) / np.sqrt(n)\n",
    "        Z3 = np.random.randn(n, p_list[2]) / np.sqrt(n)\n",
    "\n",
    "        X1 = (1/n) * U1 @ D1 @ V1.T + Z1\n",
    "        X2 = (1/n) * U2 @ D2 @ V2.T + Z2\n",
    "        X3 = (1/n) * U3 @ D3 @ V3.T + Z3\n",
    "        X_list = [X1, X2, X3]\n",
    "        K_list = r_list\n",
    "\n",
    "        # --- AMP with clustering (HSS) ---\n",
    "        pipe_cluster = MultimodalPCAPipelineClustering()\n",
    "        result_cluster = pipe_cluster.denoise_amp(\n",
    "            X_list, K_list,\n",
    "            compute_clusters=True,\n",
    "            amp_iters=amp_iters,\n",
    "            similarity_method=\"cca\"\n",
    "        )\n",
    "        U_cluster = result_cluster[\"U_denoised\"]\n",
    "\n",
    "        # --- AMP without clustering (distinct) ---\n",
    "        pipe_distinct = MultimodalPCAPipeline()\n",
    "        result_distinct = pipe_distinct.denoise_amp(\n",
    "            X_list, K_list,\n",
    "            cluster_labels_U=np.array([0, 1, 2]),\n",
    "            amp_iters=amp_iters\n",
    "        )\n",
    "        U_distinct = result_distinct[\"U_denoised\"]\n",
    "\n",
    "        # === Compare other multimodal methods on all three blocks ===\n",
    "        # prepare inputs\n",
    "        views = [X1, X2, X3]\n",
    "        # AJIVE\n",
    "        model_ajive = AJIVEreconstructor(rank_list=[r_list[0], r_list[1], r_list[2]], joint_rank=min(r_list[0], r_list[1], r_list[2]))\n",
    "        U_ajive, _ = model_ajive.fit(views)\n",
    "        # MCCA\n",
    "        model_mcca = MCCA_denoiser(individual_ranks=[r_list[0], r_list[1], r_list[2]], joint_rank=min(r_list))\n",
    "        U_mcca, _ = model_mcca.fit(views)\n",
    "        # GCCA\n",
    "        model_gcca = GCCA_denoiser(individual_ranks=[r_list[0], r_list[1], r_list[2]], joint_rank=min(r_list))\n",
    "        U_gcca, _ = model_gcca.fit(views)\n",
    "        # DISCO\n",
    "        print(min(r_list))\n",
    "        model_disco = DISCO_denoiser(individual_ranks=[r_list[0], r_list[1], r_list[2]], n_components=min(r_list))\n",
    "        U_disco, _ = model_disco.fit(views)\n",
    "        # MFA\n",
    "        model_mfa = MFA_denoiser(individual_ranks=[r_list[0], r_list[1], r_list[2]], joint_rank=min(r_list))\n",
    "        U_mfa, _ = model_mfa.fit(views)\n",
    "        # HPCA\n",
    "        model_hpca = HPCA_denoiser(joint_rank=min(r_list), individual_ranks=[r_list[0], r_list[1], r_list[2]])\n",
    "        hpca_fit = model_hpca.fit(views)\n",
    "        U_hpca, _ = hpca_fit.get_denoised_factors()\n",
    "\n",
    "        # accumulate errors for each method on blocks 0, 1, and 2\n",
    "        errors_ajive[0].append(reconstruction_error(U_ajive[0], U1))\n",
    "        errors_ajive[1].append(reconstruction_error(U_ajive[1], U2))\n",
    "        errors_ajive[2].append(reconstruction_error(U_ajive[2], U3))\n",
    "\n",
    "        errors_mcca[0].append(reconstruction_error(U_mcca[0], U1))\n",
    "        errors_mcca[1].append(reconstruction_error(U_mcca[1], U2))\n",
    "        errors_mcca[2].append(reconstruction_error(U_mcca[2], U3))\n",
    "\n",
    "        errors_gcca[0].append(reconstruction_error(U_gcca[0], U1))\n",
    "        errors_gcca[1].append(reconstruction_error(U_gcca[1], U2))\n",
    "        errors_gcca[2].append(reconstruction_error(U_gcca[2], U3))\n",
    "\n",
    "        errors_disco[0].append(reconstruction_error(U_disco[0], U1))\n",
    "        errors_disco[1].append(reconstruction_error(U_disco[1], U2))\n",
    "        errors_disco[2].append(reconstruction_error(U_disco[2], U3))\n",
    "\n",
    "        errors_mfa[0].append(reconstruction_error(U_mfa[0], U1))\n",
    "        errors_mfa[1].append(reconstruction_error(U_mfa[1], U2))\n",
    "        errors_mfa[2].append(reconstruction_error(U_mfa[2], U3))\n",
    "\n",
    "        errors_hpca[0].append(reconstruction_error(U_hpca[0], U1))\n",
    "        errors_hpca[1].append(reconstruction_error(U_hpca[1], U2))\n",
    "        errors_hpca[2].append(reconstruction_error(U_hpca[2], U3))\n",
    "\n",
    "        # --- Reconstruction Errors ---\n",
    "        for i in range(3):\n",
    "            errors_clustered[i].append(reconstruction_error(U_cluster[i][:, :, -1], U_true[i]))\n",
    "            errors_distinct[i].append(reconstruction_error(U_distinct[i][:, :, -1], U_true[i]))\n",
    "\n",
    "    # --- Store average errors ---\n",
    "    results = {\n",
    "        \"clustered\": [np.mean(errors_clustered[i]) for i in range(3)],\n",
    "        \"distinct\": [np.mean(errors_distinct[i]) for i in range(3)]\n",
    "    }\n",
    "    # compute averages for other methods\n",
    "    results['ajive'] = [np.mean(errors_ajive[i]) for i in range(3)]\n",
    "    results['mcca']  = [np.mean(errors_mcca[i]) for i in range(3)]\n",
    "    results['gcca']  = [np.mean(errors_gcca[i]) for i in range(3)]\n",
    "    results['disco'] = [np.mean(errors_disco[i]) for i in range(3)]\n",
    "    results['mfa']   = [np.mean(errors_mfa[i]) for i in range(3)]\n",
    "    results['hpca']  = [np.mean(errors_hpca[i]) for i in range(3)]\n",
    "\n",
    "    print(f\"\\n=== For rho = {rho}, the results are {results} ===\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\">>> Script started\", flush=True)\n",
    "    load_modules()\n",
    "\n",
    "    rho = 0.8\n",
    "    n   = 1000\n",
    "    gamma_list = [0.25, 0.25, 0.5]\n",
    "    r_list     = [1, 2, 1]\n",
    "    p_list     = [int(g * n) for g in gamma_list]\n",
    "\n",
    "    res = run_amp_rho_experiment(\n",
    "        n=n,\n",
    "        p_list=p_list,\n",
    "        r_list=r_list,\n",
    "        rho=rho,\n",
    "        num_trials=30,\n",
    "        amp_iters=20,\n",
    "        num_clusters=2,\n",
    "        threshold=None\n",
    "    )\n",
    "\n",
    "    # --- Save results as CSV ---\n",
    "    rows = []\n",
    "    for method in [\"clustered\", \"distinct\"]:\n",
    "        for mod in range(3):\n",
    "            rows.append({\n",
    "                \"rho\": rho,\n",
    "                \"Method\": method,\n",
    "                \"Modality\": mod + 1,\n",
    "                \"Error\": res[method][mod]\n",
    "            })\n",
    "    # add other methods for blocks 1, 2, and 3 (modality 1, 2, and 3)\n",
    "    for method in ['ajive', 'mcca', 'gcca', 'disco', 'mfa', 'hpca']:\n",
    "        for mod in [1, 2, 3]:\n",
    "            rows.append({\n",
    "                \"rho\": rho,\n",
    "                \"Method\": method,\n",
    "                \"Modality\": mod,\n",
    "                \"Error\": res[method][mod-1]\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    os.makedirs(\"Results/vary_rho_com_meth\", exist_ok=True)\n",
    "    df.to_csv(f\"Results/vary_rho_com_meth/rho_{rho}_n_{n}.csv\", index=False)\n",
    "    print(f\">>> Results saved to Results/vary_rho_com_meth/rho_{rho}_n_{n}.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6606e16b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HierarchicalAMP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
